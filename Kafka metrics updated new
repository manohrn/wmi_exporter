from kafka import KafkaConsumer
from prometheus_client import start_http_server, Gauge
import json
import time

# Define the list of bootstrap servers
bootstrap_servers = [
    "ent-kafka-dev101.wellsfargo.com:9092",
    "ent-kafka-dev101-a.wellsfargo.com:9092",
    "ent-kafka-dev101-b.wellsfargo.com:9092"
]

# Define the topic you want to consume from
topic_name = 'netopsmetric-export'

# Create a Kafka consumer
consumer = KafkaConsumer(
    topic_name,
    bootstrap_servers=bootstrap_servers,
    auto_offset_reset='earliest',  # Start reading at the earliest available message
    enable_auto_commit=True
)

# Define Prometheus metrics
message_count = Gauge('kafka_messages_total', 'Total number of messages consumed from Kafka')
message_value = Gauge('kafka_message_value', 'Value of the last message consumed from Kafka')

# Start the Prometheus metrics server
start_http_server(8000)

def process_message(message):
    # Process the message and update Prometheus metrics
    message_count.inc()
    try:
        value = float(message.value.decode('utf-8'))
        message_value.set(value)
    except ValueError:
        print(f"Non-numeric message value: {message.value.decode('utf-8')}")

# Read messages from the topic
try:
    for message in consumer:
        process_message(message)
except KeyboardInterrupt:
    print("Stopped by user")
finally:
    # Close the consumer connection
    consumer.close()
