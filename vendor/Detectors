Hereâ€™s a detailed step-by-step guide to setting up Splunk Observability Cloud Detectors, Notification Policies, Inhibitions, Silences, Muting Rules, and REST API Integrations, including SignalFlow scripts for monitoring CPU, Memory, Disk, Swap, and Splunk OTEL Collector Health.

1. Creating Detectors in Splunk Observability Cloud

Steps to Create a Detector
	1.	Navigate to Splunk Observability Cloud â†’ Detectors.
	2.	Click â€œCreate Detectorâ€.
	3.	Choose â€œCustom SignalFlow Programâ€.
	4.	Enter Detector Name and Description.
	5.	Copy & Paste the SignalFlow Script from the sections below.
	6.	Define Alert Conditions & Notification Policies.
	7.	Save and Enable the Detector.

2. SignalFlow Scripts for Monitoring System Resources

These SignalFlow scripts create detectors for CPU, Memory, Disk, Swap Usage, and Splunk OTEL Collector Health.

A. CPU Usage Detector

cpu = data('cpu.utilization', filter=filter('host', 'your_host'))
    .mean(over='5m')

detect(when(cpu > 75, lasting='5m')).publish('High CPU Warning', severity='Warning')
detect(when(cpu > 90, lasting='3m')).publish('Critical CPU Usage', severity='Critical')

B. Memory Usage Detector

memory = data('memory.usage', filter=filter('host', 'your_host'))
    .mean(over='5m')

detect(when(memory > 80, lasting='5m')).publish('High Memory Warning', severity='Warning')
detect(when(memory > 95, lasting='3m')).publish('Critical Memory Usage', severity='Critical')

C. Disk Usage Detector

disk = data('disk.utilization', filter=filter('host', 'your_host') and filter('mount_point', '!= "/tmp"'))
    .mean(over='5m')

detect(when(disk > 75, lasting='5m')).publish('High Disk Usage Warning', severity='Warning')
detect(when(disk > 90, lasting='3m')).publish('Critical Disk Usage', severity='Critical')

D. Swap Usage Detector

swap = data('memory.swap_usage', filter=filter('host', 'your_host'))
    .mean(over='5m')

detect(when(swap > 60, lasting='5m')).publish('High Swap Usage Warning', severity='Warning')
detect(when(swap > 80, lasting='3m')).publish('Critical Swap Usage', severity='Critical')

E. Splunk OTEL Collector Self-Health Monitoring

Process Uptime

uptime = data('process.uptime', filter=filter('service', 'otel-collector'))
detect(when(uptime < 300, lasting='1m')).publish('OTEL Collector Restarted', severity='Critical')

CPU & Memory Monitoring

cpu = data('process.cpu.utilization', filter=filter('service', 'otel-collector'))
    .mean(over='5m')
memory = data('process.memory.rss', filter=filter('service', 'otel-collector'))
    .mean(over='5m')

detect(when(cpu > 60, lasting='5m')).publish('High CPU Usage for OTEL Collector', severity='Warning')
detect(when(cpu > 80, lasting='3m')).publish('Critical CPU Usage for OTEL Collector', severity='Critical')

detect(when(memory > 500000000, lasting='5m')).publish('High Memory Usage for OTEL Collector', severity='Warning')
detect(when(memory > 1000000000, lasting='3m')).publish('Critical Memory Usage for OTEL Collector', severity='Critical')

Exporter & Receiver Health

exporter_spans = data('otelcol_exporter_sent_spans', filter=filter('service', 'otel-collector'))
detect(when(exporter_spans == 0, lasting='5m')).publish('No Spans Exported by OTEL Collector', severity='Critical')

receiver_drops = data('otelcol_receiver_refused_spans', filter=filter('service', 'otel-collector'))
detect(when(receiver_drops > 0, lasting='5m')).publish('OTEL Collector Dropping Spans', severity='Warning')

3. Creating Notification Policies
	1.	Go to Observability Cloud â†’ Detectors â†’ Notification Policies.
	2.	Click â€œCreate Notification Policyâ€.
	3.	Define Scope (Choose Detectors & Conditions).
	4.	Select Notification Channels (Email, Slack, PagerDuty, Webhook).
	5.	Set Escalation Rules (e.g., Slack first, then PagerDuty if not acknowledged).
	6.	Click â€œSave Policyâ€.

4. Configuring Inhibitions
	1.	Go to Observability Cloud â†’ Detectors â†’ Inhibitions.
	2.	Click â€œCreate Inhibitionâ€.
	3.	Select â€œBlocking Alertâ€ (e.g., â€œCritical CPU Usageâ€).
	4.	Select â€œSuppressed Alertsâ€ (e.g., â€œHigh CPU Warningâ€).
	5.	Click â€œSave & Applyâ€.

âœ” Use Case: Prevent â€œHigh CPU Warningâ€ alerts if â€œCritical CPU Usageâ€ is active.

5. Creating Silences
	1.	Go to Observability Cloud â†’ Alerting â†’ Silences.
	2.	Click â€œCreate Silenceâ€.
	3.	Choose Detectors to Silence.
	4.	Set Silence Duration (e.g., 1 hour for maintenance).
	5.	Click â€œSave & Applyâ€.

âœ” Use Case: Mute alerts during planned maintenance.

6. Creating Muting Rules
	1.	Go to Observability Cloud â†’ Alerting â†’ Muting Rules.
	2.	Click â€œCreate Muting Ruleâ€.
	3.	Define Scope (e.g., environment != "production").
	4.	Click â€œSave & Applyâ€.

âœ” Use Case: Suppress alerts for non-production environments.

7. REST API Integrations

Common API Endpoints

Action	HTTP Method	Endpoint
Get all detectors	GET	/v2/detectors
Create a detector	POST	/v2/detectors
Silence an alert	POST	/v2/silences
Create a muting rule	POST	/v2/mutingRules

Example: Silence an Alert via API

curl -X POST "https://api.signalfx.com/v2/silences" \
     -H "X-SF-TOKEN: YOUR_API_KEY" \
     -H "Content-Type: application/json" \
     -d '{
           "detectorId": "123456",
           "reason": "Planned Maintenance",
           "startTime": 1711234567000,
           "endTime": 1711238567000
         }'

âœ” Use Case: Automate alert suppression via API.

8. Best Practices

âœ” Reduce Alert Noise: Use muting, inhibitions, and silences wisely.
âœ” Escalation Chains: Route alerts based on severity.
âœ” Automate via API: Use REST API for creating & managing alerts.
âœ” Test Alerts: Simulate alerts before deploying to production.

âœ… Need YAML-based detector configurations or dashboards? Let me know! ğŸš€
