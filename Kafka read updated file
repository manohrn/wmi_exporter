import csv
import json

def csv_to_custom_json_with_payload(csv_file_path, json_file_path):
    # Initialize a dictionary to store the data grouped by server_name
    result = {}

    # Open the CSV file and read its contents
    with open(csv_file_path, mode='r') as csv_file:
        csv_reader = csv.DictReader(csv_file)

        for row in csv_reader:
            # Extract the server_name as the key
            server_name = row.get("server_name")

            # Create the structure for the current server_name
            entry = {
                "labels": {
                    "os": row.get("os", "linux"),  # Default value is "linux" if not provided
                    "kafka_baseconfig": row.get("id", "default_id"),  # ID from CSV or default
                    "environment": row.get("env_name", "uts"),  # Environment from CSV or default
                    "snipetype": "kafka_exporter"  # Fixed value as per example
                },
                "template_variables": {
                    "kafka_monitors": []
                },
                "payload": {
                    "job_name": row.get("job_name"),
                    "target_name": row.get("target_name"),
                    "server_name": server_name,
                    "env_name": row.get("env_name"),
                    "fqdn_name": row.get("fqdn_name"),
                    "component_name": row.get("component_name"),
                    "component_id": int(row.get("component_id", 0)),  # Ensure component_id is an integer
                    "dc": row.get("dc")
                }
            }

            # Add Kafka Connect cluster ID only if the component is "connect"
            if row.get("component_name") == "connect":
                kafka_monitor = {
                    "job_name": row.get("job_name"),
                    "target_name": row.get("target_name"),
                    "server_name": server_name,
                    "env_name": row.get("env_name"),
                    "fqdn_name": row.get("fqdn_name"),
                    "component_name": row.get("component_name"),
                    "component_id": int(row.get("component_id", 0)),
                    "dc": row.get("dc")
                }
                entry["template_variables"]["kafka_monitors"].append(kafka_monitor)

            # Add the entry under the server_name key
            result[server_name] = entry

    # Write the final result to a JSON file
    with open(json_file_path, mode='w') as json_file:
        json.dump(result, json_file, indent=4)

    print(f"CSV data from {csv_file_path} has been converted to JSON format with payload and saved as {json_file_path}.")


# Example usage:
csv_file = "input.csv"  # Replace with your input CSV file path
json_file = "output.json"  # Replace with your desired output JSON file path
csv_to_custom_json_with_payload(csv_file, json_file)
